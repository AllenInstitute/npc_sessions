{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import np_session\n",
    "import npc_sessions\n",
    "import numpy as np\n",
    "import rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = npc_sessions.DynamicRoutingSession(\n",
    "    R'\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\pilot recordings\\2023-08-03_09-39-59_670248'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = utils.get_ephys_timing_on_pxi(session.ephys_recording_dirs)\n",
    "for device in devices:\n",
    "        (\n",
    "            ephys_barcode_times,\n",
    "            ephys_barcode_ids,\n",
    "        ) = utils.extract_barcodes_from_times(\n",
    "            on_times=device.ttl_sample_numbers[device.ttl_states > 0]\n",
    "            / device.sampling_rate,\n",
    "            off_times=device.ttl_sample_numbers[device.ttl_states < 0]\n",
    "            / device.sampling_rate,\n",
    "        )\n",
    "        plt.plot(np.diff(ephys_barcode_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_exp_recording_dirs = [utils.get_single_oebin_path(directory).parent for directory in session.ephys_record_node_dirs]\n",
    "display(tuple((device.name, device.sampling_rate, device.start_time) for device in npc_sessions.get_ephys_timing_on_sync(session.sync_path, full_exp_recording_dirs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get barcode intervals for each probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_rising = session.sync_data.get_rising_edges(0, 'seconds')\n",
    "barcode_falling = session.sync_data.get_falling_edges(0, 'seconds')\n",
    "barcode_times, barcodes = utils.extract_barcodes_from_times(barcode_rising, barcode_falling)\n",
    "\n",
    "devices_pxi = utils.get_ephys_timing_on_pxi(full_exp_recording_dirs)\n",
    "devices_sync = tuple(utils.get_ephys_timing_on_sync(session.sync_path, session.ephys_recording_dirs))\n",
    "device_barcode_dict = {}\n",
    "for device in devices_pxi:\n",
    "        if 'NI-DAQmx' in device.name or 'LFP' in device.name:\n",
    "            continue\n",
    "        \n",
    "        device_sync = [d for d in devices_sync if d.name==device.name][0]\n",
    "\n",
    "        (\n",
    "            ephys_barcode_times,\n",
    "            ephys_barcode_ids,\n",
    "        ) = utils.extract_barcodes_from_times(\n",
    "            on_times=device.ttl_sample_numbers[device.ttl_states > 0]\n",
    "            / device.sampling_rate,\n",
    "            off_times=device.ttl_sample_numbers[device.ttl_states < 0]\n",
    "            / device.sampling_rate,\n",
    "        )\n",
    "        raw = ephys_barcode_times\n",
    "        corrected = ephys_barcode_times*(30000/device_sync.sampling_rate)\n",
    "        intervals = np.diff(corrected)\n",
    "        max_deviation = np.max(np.abs(intervals - np.median(intervals)))\n",
    "\n",
    "        device_barcode_dict[device.name] = {'barcode_times_raw': raw, \n",
    "                                            'barcode_times_corrected': corrected,\n",
    "                                            'max_deviation_from_median_interval': max_deviation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches([8, 4])\n",
    "sync_intervals = np.diff(barcode_times)\n",
    "sync_max_deviation_from_median_interval = np.max(np.abs(sync_intervals - np.median(sync_intervals)))\n",
    "start_tag, end_tag = ('[bold green]', '[/bold green]') if sync_max_deviation_from_median_interval<0.001 else ('[bold magenta]', '[/bold magenta]')\n",
    "rich.print(start_tag + 'sync:  max_deviation = ' + str(sync_max_deviation_from_median_interval) + end_tag)\n",
    "\n",
    "ax[0].plot(sync_intervals)\n",
    "legend = []\n",
    "for device_name, device_data in device_barcode_dict.items():\n",
    "    ax[1].plot(np.diff(device_data['barcode_times_raw']))\n",
    "    ax[2].plot(np.diff(device_data['barcode_times_corrected']))\n",
    "    legend.append(device_name.split('Probe')[1])\n",
    "    max_deviation = device_data['max_deviation_from_median_interval']\n",
    "    start_tag, end_tag = ('[bold green]', '[/bold green]') if max_deviation<0.001 else ('[bold magenta]', '[/bold magenta]')\n",
    "    rich.print(start_tag + device_name + ':  max_deviation = ' + str(max_deviation) + end_tag)\n",
    "\n",
    "\n",
    "\n",
    "ax[2].plot(sync_intervals, 'k')\n",
    "ax[2].legend(legend + ['sync'])\n",
    "ax[0].set_title('Sync Barcode Intervals')\n",
    "ax[1].set_title('Probe Barcode Intervals')\n",
    "ax[2].set_title('Probe Barcode Intervals Corrected')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stim frame intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.print('[bold] Fraction long frames [/bold]')\n",
    "for stim_name, stim_times in stim_display_times.items():\n",
    "    intervals = np.diff(stim_times)\n",
    "    fraction_long = np.sum(intervals>0.02)/len(intervals)\n",
    "    longest_interval = max(intervals)\n",
    "    start_tag, end_tag = ('[bold green]', '[/bold green]') if fraction_long<0.01 and longest_interval<0.5 else ('[bold magenta]', '[/bold magenta]')\n",
    "    rich.print(start_tag + stim_name.stem.split('_')[0] + ': ' + str(fraction_long) + ' \\t\\t longest interval:' + str(longest_interval) + end_tag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = session.sync_data.plot_diode_measured_sync_square_flips()\n",
    "stim_display_times = npc_sessions.get_stim_frame_times(*session.stim_paths, sync=session.sync_data)\n",
    "names = tuple(k for k, v in stim_display_times.items() if v is not None)\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.set_title(names[idx].stem.split('_')[0])\n",
    "fig.set_size_inches(12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hist, axes_hist = plt.subplots(1, len(axes))\n",
    "fig_hist.set_size_inches(12, 6)\n",
    "\n",
    "for ax, (stim_name, stim_times) in zip(axes_hist, stim_display_times.items()):\n",
    "    ax.hist(np.diff(stim_times), bins=np.arange(0, 0.1, 0.001))\n",
    "    ax.set_yscale('log')\n",
    "    ax.axvline(1/60, c='k', ls='dotted')\n",
    "    ax.set_title(stim_name.stem.split('_')[0])\n",
    "    ax.set_xlabel('time (s)')\n",
    "    ax.set_ylabel('frame interval count')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = session.sync_data.plot_stim_onsets()\n",
    "names = tuple(k for k, v in stim_display_times.items() if v is not None)\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.set_title(names[idx].stem.split('_')[0])\n",
    "fig.set_size_inches(10, 5 * len(axes))\n",
    "fig.subplots_adjust(hspace=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "\n",
    "for info in session.video_info_data.values():\n",
    "    print(info['CameraLabel']), display(IPython.display.JSON(\n",
    "        {\n",
    "            k:v\n",
    "            for k,v in info.items() \n",
    "            if k in ('FPS', 'Duration', 'FramesRecorded', 'FramesLostCount')\n",
    "        } | {'Lost': f\"{100 * info['FramesLostCount'] / info['FramesRecorded']:.5f}%\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = session.video_paths[0]\n",
    "v = cv2.VideoCapture(video_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.get(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import io\n",
    "from typing import Literal, TypeVar\n",
    "\n",
    "import upath\n",
    "\n",
    "def camera_frame_grabs_simple(\n",
    "    paths: Iterable[upath.UPath],\n",
    "    num_frames_to_grab: int = 5,\n",
    ") -> None:\n",
    "    \"\"\"Just plots evenly spaced frames, no concept of epochs.\n",
    "    \n",
    "    video frames across cameras aren't synced .\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=[10, 3 * len(paths)], constrained_layout=True, facecolor='0.5')\n",
    "    gs = gridspec.GridSpec(len(paths), num_frames_to_grab, figure=fig)\n",
    "    gs.update(wspace=0.0, hspace=0.0)\n",
    "    for idx, video_path in enumerate(paths):\n",
    "        # get frames to plot\n",
    "        v = cv2.VideoCapture(video_path.as_posix()) # TODO open with upath from cloud\n",
    "        \n",
    "        frame_delta = np.ceil(v.get(cv2.CAP_PROP_FRAME_COUNT) / num_frames_to_grab + 1)\n",
    "        frames_of_interest = np.arange(v.get(cv2.CAP_PROP_FPS), v.get(cv2.CAP_PROP_FRAME_COUNT), frame_delta)\n",
    "\n",
    "        for i, f in enumerate(frames_of_interest):\n",
    "            v.set(cv2.CAP_PROP_POS_FRAMES, int(f))\n",
    "            ret, frame = v.read()\n",
    "            ax = fig.add_subplot(gs[idx, i])\n",
    "            ax.imshow(frame)\n",
    "            # ax.axis('off')\n",
    "            ax.tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False,\n",
    "            )\n",
    "            ax.set_title(datetime.timedelta(seconds=f/v.get(cv2.CAP_PROP_FPS)), fontsize=10)\n",
    "    return fig\n",
    "\n",
    "def get_total_frames_in_video(\n",
    "    paths: Iterable[upath.UPath],\n",
    "    num_frames_to_grab: int = 5,\n",
    ") -> dict[Literal[\"behavior\", \"eye\", \"face\"], int]:\n",
    "    frame_count_dict = {}\n",
    "    for idx, video_path in enumerate(paths):\n",
    "        v = cv2.VideoCapture(video_path.as_posix()) # TODO open with upath from cloud\n",
    "        num_frames = v.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        cam_name = npc_sessions.extract_camera_name(video_path)\n",
    "        frame_count_dict[cam_name] = int(num_frames)\n",
    "    \n",
    "    return frame_count_dict\n",
    "\n",
    "fig = camera_frame_grabs_simple(session.video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify frame times can be found on sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npc_sessions.get_video_frame_times(session.sync_data, *session.video_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_info = {}\n",
    "for info in session.video_info_data.values():\n",
    "    camera_info[info['CameraLabel'].lower()] = {\n",
    "        \n",
    "            k:v\n",
    "            for k,v in info.items() \n",
    "            if k in ('FPS', 'Duration', 'FramesRecorded', 'FramesLostCount', 'LostFrames')\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npc_sessions import get_cam_exposing_times_on_sync\n",
    "from npc_sessions.utils.mvr import get_cam_transfer_times_on_sync\n",
    "from npc_sessions.utils.mvr import get_cam_exposing_falling_edge_times_on_sync\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_exposing_times = get_cam_exposing_times_on_sync(session.sync_data)\n",
    "cam_transfer_times = get_cam_transfer_times_on_sync(session.sync_data)\n",
    "cam_exposing_falling_edge_times = get_cam_exposing_falling_edge_times_on_sync(session.sync_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_in_videos = get_total_frames_in_video(session.video_paths)\n",
    "for camera, info in camera_info.items():\n",
    "    frames_recorded = info['FramesRecorded']\n",
    "    frames_lost = info['FramesLostCount']\n",
    "    num_exposures = cam_exposing_times[camera].size\n",
    "    num_transfers = cam_transfer_times[camera].size\n",
    "\n",
    "    num_frames_in_video = frames_in_videos[camera]\n",
    "    num_expected_from_sync = num_transfers - frames_lost + 1\n",
    "    signature_exposures = cam_exposing_falling_edge_times[camera][:10] - cam_exposing_times[camera][:10]\n",
    "    \n",
    "    info['num_frames_exposed'] = num_exposures\n",
    "    info['num_frames_transfered'] = num_transfers\n",
    "    info['num_frames_in_video'] = num_frames_in_video\n",
    "    info['num_expected_from_sync'] =num_expected_from_sync\n",
    "    info['expected_minus_actual'] = num_expected_from_sync - num_frames_in_video\n",
    "    info['signature_exposure_duration'] = np.round(np.median(signature_exposures), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('npc_sessions')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ec83c3f857dcc2abca66b519bdf8c0c7b61bc788849117c28e9ccf4914a1f09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
