{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import npc_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npc_sessions import utils\n",
    "import numpy as np\n",
    "import rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = npc_sessions.Session(\n",
    "    R'\\\\allen\\programs\\mindscope\\workgroups\\templeton\\TTOC\\pilot recordings\\2023-08-03_09-39-59_670248'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some stuff to help print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tag = '[bold red]'\n",
    "good_tag = '[bold green]'\n",
    "cautious_tag = '[bold yellow]'\n",
    "\n",
    "def bad_string(base: str):\n",
    "    return bad_tag + base + bad_tag\n",
    "\n",
    "def good_string(base: str):\n",
    "    return good_tag + base + good_tag\n",
    "\n",
    "def cautious_string(base: str):\n",
    "    return cautious_tag + base + cautious_tag\n",
    "\n",
    "def determine_string_valence(value, good_criterion, bad_criterion):\n",
    "    if good_criterion:\n",
    "        return good_string\n",
    "\n",
    "    elif bad_criterion:\n",
    "        return bad_string\n",
    "\n",
    "    else:\n",
    "        return cautious_string\n",
    "\n",
    "def add_valence_to_string(basestring: str, value: float | int, good_criterion: bool, bad_criterion: bool) -> str:\n",
    "\n",
    "    valence_func = determine_string_valence(value, good_criterion, bad_criterion)\n",
    "\n",
    "    return valence_func(basestring)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = utils.get_ephys_timing_on_pxi(session.ephys_recording_dirs)\n",
    "for device in devices:\n",
    "        (\n",
    "            ephys_barcode_times,\n",
    "            ephys_barcode_ids,\n",
    "        ) = utils.extract_barcodes_from_times(\n",
    "            on_times=device.ttl_sample_numbers[device.ttl_states > 0]\n",
    "            / device.sampling_rate,\n",
    "            off_times=device.ttl_sample_numbers[device.ttl_states < 0]\n",
    "            / device.sampling_rate,\n",
    "        )\n",
    "        plt.plot(np.diff(ephys_barcode_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_exp_recording_dirs = [utils.get_single_oebin_path(directory).parent for directory in session.ephys_record_node_dirs]\n",
    "display(tuple((device.name, device.sampling_rate, device.start_time) for device in npc_sessions.get_ephys_timing_on_sync(session.sync_path, full_exp_recording_dirs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get barcode intervals for each probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_rising = session.sync_data.get_rising_edges(0, 'seconds')\n",
    "barcode_falling = session.sync_data.get_falling_edges(0, 'seconds')\n",
    "barcode_times, barcodes = utils.extract_barcodes_from_times(barcode_rising, barcode_falling)\n",
    "\n",
    "devices_pxi = utils.get_ephys_timing_on_pxi(full_exp_recording_dirs)\n",
    "devices_sync = tuple(utils.get_ephys_timing_on_sync(session.sync_path, session.ephys_recording_dirs))\n",
    "device_barcode_dict = {}\n",
    "for device in devices_pxi:\n",
    "        if 'NI-DAQmx' in device.name or 'LFP' in device.name:\n",
    "            continue\n",
    "        \n",
    "        device_sync = [d for d in devices_sync if d.name==device.name][0]\n",
    "\n",
    "        (\n",
    "            ephys_barcode_times,\n",
    "            ephys_barcode_ids,\n",
    "        ) = utils.extract_barcodes_from_times(\n",
    "            on_times=device.ttl_sample_numbers[device.ttl_states > 0]\n",
    "            / device.sampling_rate,\n",
    "            off_times=device.ttl_sample_numbers[device.ttl_states < 0]\n",
    "            / device.sampling_rate,\n",
    "        )\n",
    "        raw = ephys_barcode_times\n",
    "        corrected = ephys_barcode_times*(30000/device_sync.sampling_rate)\n",
    "        intervals = np.diff(corrected)\n",
    "        max_deviation = np.max(np.abs(intervals - np.median(intervals)))\n",
    "\n",
    "        device_barcode_dict[device.name] = {'barcode_times_raw': raw, \n",
    "                                            'barcode_times_corrected': corrected,\n",
    "                                            'max_deviation_from_median_interval': max_deviation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot barcode intervals for sync and for each probe after sample rate correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3)\n",
    "fig.set_size_inches([8, 4])\n",
    "sync_intervals = np.diff(barcode_times)\n",
    "sync_max_deviation_from_median_interval = np.max(np.abs(sync_intervals - np.median(sync_intervals)))\n",
    "sync_max_deviation_string =  add_valence_to_string(f'Sync deviation: {sync_max_deviation_from_median_interval}',\n",
    "                                                        sync_max_deviation_from_median_interval,\n",
    "                                                        sync_max_deviation_from_median_interval<0.001,\n",
    "                                                        sync_max_deviation_from_median_interval>0.001)\n",
    "rich.print(sync_max_deviation_string)\n",
    "\n",
    "ax[0].plot(sync_intervals)\n",
    "legend = []\n",
    "for device_name, device_data in device_barcode_dict.items():\n",
    "    ax[1].plot(np.diff(device_data['barcode_times_raw']))\n",
    "    ax[2].plot(np.diff(device_data['barcode_times_corrected']))\n",
    "    legend.append(device_name.split('Probe')[1])\n",
    "    max_deviation = device_data['max_deviation_from_median_interval']\n",
    "    max_deviation_string =  add_valence_to_string(f'{device_name}: {max_deviation}',\n",
    "                                                        max_deviation,\n",
    "                                                        max_deviation<0.001,\n",
    "                                                        max_deviation>0.001)\n",
    "    \n",
    "    rich.print(max_deviation_string)\n",
    "\n",
    "\n",
    "\n",
    "ax[2].plot(sync_intervals, 'k')\n",
    "ax[2].legend(legend + ['sync'])\n",
    "ax[0].set_title('Sync Barcode Intervals')\n",
    "ax[1].set_title('Probe Barcode Intervals')\n",
    "ax[2].set_title('Probe Barcode Intervals Corrected')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stim timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot vsync times and diode flips for the beginnings and ends of each stimulus epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.print('[bold] Fraction long frames [/bold]')\n",
    "for stim_name, stim_times in stim_display_times.items():\n",
    "    intervals = np.diff(stim_times)\n",
    "    fraction_long = np.sum(intervals>0.02)/len(intervals)\n",
    "    longest_interval = max(intervals)\n",
    "    start_tag, end_tag = ('[bold green]', '[/bold green]') if fraction_long<0.01 and longest_interval<0.5 else ('[bold magenta]', '[/bold magenta]')\n",
    "    rich.print(start_tag + stim_name.stem.split('_')[0] + ': ' + str(fraction_long) + ' \\t\\t longest interval:' + str(longest_interval) + end_tag)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot diode flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = session.sync_data.plot_diode_measured_sync_square_flips()\n",
    "stim_display_times = npc_sessions.get_stim_frame_times(*session.stim_paths, sync=session.sync_data)\n",
    "names = tuple(k for k, v in stim_display_times.items() if v is not None)\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.set_title(names[idx].stem.split('_')[0])\n",
    "fig.set_size_inches(12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot histogram of vsync intervals\n",
    "TO DO: add histogram of diode flip intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hist, axes_hist = plt.subplots(1, len(axes))\n",
    "fig_hist.set_size_inches(12, 6)\n",
    "\n",
    "for ax, (stim_name, stim_times) in zip(axes_hist, stim_display_times.items()):\n",
    "    ax.hist(np.diff(stim_times), bins=np.arange(0, 0.1, 0.001))\n",
    "    ax.set_yscale('log')\n",
    "    ax.axvline(1/60, c='k', ls='dotted')\n",
    "    ax.set_title(stim_name.stem.split('_')[0])\n",
    "    ax.set_xlabel('time (s)')\n",
    "    ax.set_ylabel('frame interval count')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = session.sync_data.plot_stim_onsets()\n",
    "names = tuple(k for k, v in stim_display_times.items() if v is not None)\n",
    "for idx, ax in enumerate(axes):\n",
    "    ax.set_title(names[idx].stem.split('_')[0])\n",
    "fig.set_size_inches(10, 5 * len(axes))\n",
    "fig.subplots_adjust(hspace=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot indicating where long frames happened relative to stim times during task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate report indicating how many long frames we got and whether there were weird things with the diode (vsync number vs diode flip number, how many blips we got on the diode line etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sound latencies/durations across session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "\n",
    "for info in session.video_info_data.values():\n",
    "    print(info['CameraLabel']), display(IPython.display.JSON(\n",
    "        {\n",
    "            k:v\n",
    "            for k,v in info.items() \n",
    "            if k in ('FPS', 'Duration', 'FramesRecorded', 'FramesLostCount')\n",
    "        } | {'Lost': f\"{100 * info['FramesLostCount'] / info['FramesRecorded']:.5f}%\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot frames taken across session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import io\n",
    "from typing import Literal, TypeVar\n",
    "\n",
    "import upath\n",
    "\n",
    "def camera_frame_grabs_simple(\n",
    "    paths: Iterable[upath.UPath],\n",
    "    num_frames_to_grab: int = 5,\n",
    ") -> None:\n",
    "    \"\"\"Just plots evenly spaced frames, no concept of epochs.\n",
    "    \n",
    "    video frames across cameras aren't synced .\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=[10, 3 * len(paths)], constrained_layout=True, facecolor='0.5')\n",
    "    gs = gridspec.GridSpec(len(paths), num_frames_to_grab, figure=fig)\n",
    "    gs.update(wspace=0.0, hspace=0.0)\n",
    "    for idx, video_path in enumerate(paths):\n",
    "        # get frames to plot\n",
    "        v = cv2.VideoCapture(video_path.as_posix()) # TODO open with upath from cloud\n",
    "        \n",
    "        frame_delta = np.ceil(v.get(cv2.CAP_PROP_FRAME_COUNT) / num_frames_to_grab + 1)\n",
    "        frames_of_interest = np.arange(v.get(cv2.CAP_PROP_FPS), v.get(cv2.CAP_PROP_FRAME_COUNT), frame_delta)\n",
    "\n",
    "        for i, f in enumerate(frames_of_interest):\n",
    "            v.set(cv2.CAP_PROP_POS_FRAMES, int(f))\n",
    "            ret, frame = v.read()\n",
    "            ax = fig.add_subplot(gs[idx, i])\n",
    "            ax.imshow(frame)\n",
    "            # ax.axis('off')\n",
    "            ax.tick_params(\n",
    "                top=False,\n",
    "                bottom=False,\n",
    "                left=False,\n",
    "                right=False,\n",
    "                labelleft=False,\n",
    "                labelbottom=False,\n",
    "            )\n",
    "            ax.set_title(datetime.timedelta(seconds=f/v.get(cv2.CAP_PROP_FPS)), fontsize=10)\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = camera_frame_grabs_simple(session.video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify frame times can be found on sync: generate report describing frame rate/lost frames/discrepancy between frames expected from sync and frames in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npc_sessions.utils.mvr import get_augmented_camera_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_camera_info = get_augmented_camera_info(session.sync_data, *session.video_paths)\n",
    "\n",
    "for camera, info in augmented_camera_info.items():\n",
    "    rich.print(f'[bold]{camera} camera stats[bold]')\n",
    "    \n",
    "    frame_rate = info['FPS']\n",
    "    frame_rate_string = add_valence_to_string(f'Frame Rate: {frame_rate} \\t',\n",
    "                                                frame_rate,\n",
    "                                                abs(frame_rate-60)<0.01, \n",
    "                                                abs(frame_rate-60)>0.05)\n",
    "    \n",
    "    lost_frame_percentage = 100 * info['FramesLostCount'] / info['FramesRecorded']\n",
    "    lost_frame_string = add_valence_to_string(f'Lost frame percentage: {np.round(lost_frame_percentage, 3)} \\t',\n",
    "                                                lost_frame_percentage,\n",
    "                                                lost_frame_percentage<0.01, \n",
    "                                                lost_frame_percentage>0.05)\n",
    "\n",
    "    frame_diff_from_expected = info['expected_minus_actual']\n",
    "    frame_diff_string = add_valence_to_string(f'Frames expected minus actual: {frame_diff_from_expected}',\n",
    "                                                frame_diff_from_expected,\n",
    "                                                abs(frame_diff_from_expected)<1, \n",
    "                                                abs(frame_diff_from_expected)>10)\n",
    "\n",
    "\n",
    "\n",
    "    rich.print(frame_rate_string + lost_frame_string + frame_diff_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot video frames that should have licks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lick_times = session._licks.timestamps\n",
    "video_frame_times = npc_sessions.get_video_frame_times(session.sync_data, *session.video_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drift raster for each probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality metric histograms for each probe (isi violoations, amplitude cutoff, drift ptp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all spike histograms for each probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot behavior across blocks (Plots in Ethan's notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot lick latencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative reward volume over session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot running across session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Sync Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate report showing 1) number of edges, 2) median edge interval 3) overall edge frequency for each data line in sync file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('npc_sessions')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ec83c3f857dcc2abca66b519bdf8c0c7b61bc788849117c28e9ccf4914a1f09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
